# 基于内容和知识的推荐

​		协同过滤算法只要依赖于对用户和项目交互行为数据的挖掘，不可避免会存在冷启动的问题：新用户或新项目。

​		**项目冷启动：**项目冷启动常见于不断会有大量新的项目产生并加入到平台的场景下，由于没有与其相关的行为数据，协同过滤算法无法将其推荐给用户。比如：新闻资讯、短视频等项目推荐。

​		**用户冷启动：**常见于低频消费的商品，由于缺少用户的历史行为数据或是用户的历史行为数据过于久远已经没有参考价值，所以无法从交互行为数据中挖掘出用户的偏好，协同过滤算法无法对其进行推荐。比如：房产、汽车等等。



## 1. 基于内容的推荐系统框架

​		基于内容的推荐系统主要在于挖掘用户偏好特征和项目内容特征，以及它们的匹配程度，并据此为用户推荐新的其可能感兴趣的项目。具体而言，基于内容的推荐系统通过分析用户之前有过正反馈的项目内容，并且基于这些项目的内容特征建立用户模型或者画像。产生推荐的主要过程是将用户画像和项目的内容特征进行匹配，以得到用户对候选项目的感兴趣程度。

​		基于内容的推荐系统主要包括三个部分：项目建模、用户建模和产生推荐。

​		**项目建模：**主要是从项目的相关信息中提取项目的特征来对项目进行表示，即对项目的相关信息进行分析与表示。实际应用中往往利用一些用以描述项目的属性。这些属性包括结构化属性和非结构化属性。

​		**用户建模：**主要是根据用户的行为数据对用户进行建模。用户建模就是通过用户过去的喜好判断，为他产生一个标识（模型）。有了这个用户表示，就可以据此来判断用户是否会喜欢一个新的项目。当用户的历史行为数据较少时，可以直接将用户的历史行为信息作为用户的表示；当用户的历史行为数据较多时，可以通过机器学习构建用户建模，评分预测问题采用回归模型（如线性回归、$SVM$回归、决策树回归等），$Top-N$ 推荐问题采用分类模型（如逻辑回归、神经网络、$SVM$、决策树等），并利用用户的行为数据训练模型。

​		**产生推荐：**主要将用户画像和项目画像在表示空间中进行匹配，并为用户推荐与其匹配的项目。其基本思想为针对相似项目，用户将会给出相似反馈（或评分）。



​		基于内容的推荐关键在于对用户兴趣特征和项目属性特征进行建模，特别针对非结构化属性数据的分析。鉴于目前的推荐应用中，文本数据是最为常见也是相对容易获取得到的项目内容，所以接下来将主要介绍如何对文本内容进行分析和表示。

​		现在基于内容的推荐，不论是基于词向量空间模型表示文本，还是基于语义的内容相似度表示文本，都会用到和 $NLP$ 相关的很多技术，比如词嵌入技术、预训练模型、文本相似度计算等等。



## 2. 基于词向量空间模型的表示文本

​		向量空间模型是一种把文本内容表示为标识符（如索引）向量的代数模型。在推荐领域中，可以将项目的非结构化文本描述数据进行向量化表示，使其具备可计算性。最常用的文本向量空间模型是基于关键词的向量空间模型，即以关键词作为标识符。

#### 2.1 词袋模型

​		词袋模型是一种将常用的文本进行向量化表示模型。词袋模型假设对于一个文本文档，忽略其中的词序、语法、句法等要素，将其仅作为是由若干词构成的一个集合，且文档中每个词的出现是独立的，不依赖于其他词是否出现，即不考虑文本中词与词之间的上下文关系。

​		词袋模型假设文本中的词相互独立，忽略文本的句法、结构和上下文。虽然这种表示看起来并不合理，但是在实际应用中效果却很好，常用于文本分类。



#### 2.2 TF-IDF 模型

​		词袋模型中假设文档中的每一个词对于文档表示的重要程度相同，这一假设并不合理。如果将所有词同等看待，那么表示文档受热门或是常用词的影响较大。此外，词袋模型假设不同长度的文档中同一词出现次数的影响相同，这一假设也不合理，因为同一个词语在文档里出现的次数可能会比短文档跟大。

​		$TF-IDF$ 模型，该模型假设词的重要性会随着它在文档中出现的次数成正比增加，但同时也会随着它在语料库中出现的频率和文档长度成反比下降。

​		$TF$ 表示词频，指某一词在指定文档中出现的频率。一般认为，词频越高，该词越重要。为了防止它偏向长文档，通常需要对其进行归一化处理（也就是除以文档长度），$TF$ 表示词在文档中出现的次数除以文档长度。$TF(t_i,d_j)=\frac{n_{ij}}{\sum_kn_{kj}}$

​		$IDF$ 表示逆文档频率，是一种用来表示词语普遍重要性的度量，用来缓解常用词的影响。其基本思想是如果一个词在预料库中出现的频率越高，即包含该词的文本数量越多，则词普遍性越高，对应词的重要性越低。$IDF(t_i)=\log \frac{N}{n_i}$
$$
TF-IDF(t_i,d_j)=TF(t_i,d_j)\log \frac{N}{n_i}
$$


#### 2.3 模型改进

​		不管是词袋模型还是 $TF-IDF$ 模型，包含所有词的文档向量表示通常会非常长并且很稀疏。为了简化计算过程，在使用过程中，可以采用以下一些方法对模型进行改进。

- **去停用词：** 停用词是指不具备文档区分度的词语；
- **词干还原：**用单词的词干替换单词的变体；
- **使用词组（短语）：**将词组作为附加索引项加入到文档向量表示中能够进一步提高描述准确性；
- **特征选择：**在对文本进行向量表示时，选取 $n$ 个最具有代表性的词对文本进行表示，去掉文本中的噪声。



#### 2.4 余弦相似度

​		相比于基于欧氏距离的相似度，余弦相似度能够避免文档长度对文档相似度的影响。



## 3. 基于语义的内容相似度

​		基于关键词的文本表示模型虽然思想简单、实现容易，但是其只关注于词形，而忽略了词义，导致无法准确的计算一些文本的相似度，为了解决这个问题，可以采用基于语义的文本相似度计算模型。

​		基于语义的文本相似度计算模型可以分为两大类：基于知识的模型和基于语料库的模型。根据知识库的形式，基于知识库的模型又可以细分为两类，基于本体的模型和基于网络知识的模型。



#### 3.1 基于本体的文本相似度

​		基于本体的文本相似度计算模型主要是基于本体库或语义信息网络构造的。常见的本体库或语义信息网络有 $WordNet、HowNet$ 等通用本体库或语义信息网络。

​		基于本体的文本相似度计算可以分为两步：1. 计算词对之间的相似度；2. 计算文本之间的相似度；
$$
sim(d_1,d_2)=\frac{\sum_{w_i\in d_1}\sum_{w_j\in d_2}\alpha_{i1}.\alpha_{j2}.sim(w_i,w_j)}{\sum_{w_i\in d_1}\sum_{w_j\in d_2}\alpha_{i1}.\alpha_{j2}}
$$
​		其中，$\alpha_{i1}$ 和 $\alpha_{j2}$ 分别表示词 $w_i$ 和 $w_j$ 在文档 $d_1$ 和 $d_2$ 中的重要程度。

​		基于本体或语义信息网络的文本相似度计算关键在于计算词对（词与词）之间的相似度，可以借助本体库或语义信息网络的知识拓扑结构来计算词之间的相似度。当本体或语义信息网络较为完备时，基于拓扑结构的相似度可靠性较高。但是实际中的本体库或语义信息网络，由于构建困难、更新慢，导致其并不完备，进而导致基于拓扑结构的相似度计算并不可靠。



#### 3.2 基于网络知识的文本相似度

​		针对基于本题库或语义信息中实体不全、更新慢等问题，可以采用基于网络知识的模型来计算文本之间的相似度。相比于本体库或语义信息网络，网络知识的覆盖面更广、更新速度更快。



#### 3.3 基于语料库的文本相似度

​		相比于人工整理的网路知识库，语料库（文档集合）更容易获取，且覆盖面更为全面。基于语料库的文本相似度度量方法的基本思想是：利用词汇在预料库中的共现特征来计算词对相似度。

​		

## 4. 基于知识的推荐

​		基于内容的推荐可以解决项目冷启动的问题，但是无法解决用户冷启动的问题。基于知识的推荐利用用户的显示需求与专业领域知识进行推荐。

​		基于知识的推荐的基本流程为：**首先，收集用户的显式需求；然后，根据用户需求结合领域知识寻找匹配的候选项目；在找不到完全匹配的项目的情况下，自动修复项目与需求之间的不一致性，并给出合理的推荐列表。**

​		基于知识的推荐可以分为三大类：基于约束的推荐、基于效用的推荐、基于实例的推荐。三类方法的主要区别是如何使用锁提供的领域知识表示用户需求并计算其与候选项目的匹配度。



#### 4.1 基于约束的推荐

​		基于约束的推荐的目标是针对用户对项目属性取值给出一组范围（限制取值范围），寻找满足这些约束的项目子集。从理论上讲，这可以看作是一个约束满足问题，从实现上来讲，这可以看作是一个数据库的联合查询问题。

​		实际应用中，用户总是希望能够以较低的成本（如价格）获得较高质量或性能的项目，当用户对项目领域了解不够时，通常给出的约束集是不切实际的，即根据用户给定的约束集，找不到满足要求的项目。

​		为了解决因约束冲突导致项目集为空的问题，有两种常用的解决方案。一种解决方案是首先找出造成项目集合为空的约束冲突集，然后通过去除这些冲突集中的一些约束，以打破冲突，进而得到无冲突的约束集合。这种方案的关键是寻找冲突集合。



#### 4.2 基于效用的推荐

​		基于效用的推荐可以看作是将绝对的约束（是否满足）转换为定量的效用的效用（满意度）。基于效用的推荐的基本思想是利用多属性效用理论，基于预先定义的用户效用函数评估候选项目的效用值，并据此作出推荐。每个项目都将根据预定义的维度集进行评估。

​		虽然，相比于基于约束的推荐，基于效用的推荐不存在约束冲突的问题，但是基于效用的推荐需要预先给定项目在各个维度上的满意度和用户对各个维度的兴趣度。



#### 4.3 基于实例的推荐

​		基于实例的推荐可以看作是基于约束推荐的一个特例：每个属性只取一个具体的值，目标是去寻找和这个实例的属性完全一样或是相近的项目子集，其关键在于根据项目属性值计算项目之间的相似度。

​		基于实例的推荐本质上是使用相似度度量对候选项目进行检索和排序。相似度可以描述项目属性与给定用户需求度之间的匹配程度。基于实例的推荐中，用户的需求是采用实例描述的方式给出。候选项目 $p$ 和用户需求 $REQ$ 之间的相似度（匹配度）通常采用下面的方式进行计算：
$$
similarity(p,REQ)=\frac{\sum_{r\in REQ}w_r\times sim(p,r)}{\sum_{r\in REQ}w_r}
$$
​		在实际的应用中，针对数值型的属性，可以分为三大类：**越大越好（MIB）**、**越小越好（LIB）**、**越接近越好（CIB）**，不同的属性可以采用不同的计算方式来确定属性的相似度。
$$
MIB\ 属性：sim(p,r)=\frac{\phi_r(p)-min(r)}{max(r)-min(r)}\\LIB\ 属性：sim(p,r)=\frac{max(r)-\phi_r(p)}{max(r)-min(r)}\\CIB\ 属性：sim(p,r)=1-\frac{|\phi_r(p)-r|}{max(r)-min(r)}
$$
