# 基于模型的协同过滤

​		虽然基于邻域的协同过滤算法思想简单，可解释性比较强，但是在推荐的时候，需要在内存中存储整个数据集（评分矩阵或者行为矩阵），导致计算复杂度很高。基于模型的协同过滤能很好地解决这个问题，这类算法依托于机器学习模型，离线进行模型训练。在线进行推荐时，只需要存储少量的模型参数。

## 1. 基于关联规则的协同过滤

​		关联规则分析是数据挖掘研究的一个非常重要的方向，可以利用关联规则挖掘来为推荐系统助力。一旦获得了大量可靠的关联规则，便可以根据用户当前的状态和历史行为信息做合理的推荐。

​		有关关联规则挖掘算法的具体内容，可以参见数据挖掘相关数据和博客。

​		基于关联规则的推荐算法希望通过虚寻找频繁项集发现有价值的关联规则，从而实现以关联规则为依据的推荐。关联规则实际上表达了项目之间的某种相似性。但是这种相似性是指整个数据集中的相似，与个人偏好无关，是一种全局范围下的相似，因此关联规则是一种全局模型，缺乏个性化，适合超市购物、汽车导航和交通规划等应用场景。



## 2. 基于矩阵分解的协同过滤

​		用户行为数据除了可以表示为 交易数据集、评分数据集、网络图，另外一种常用的表示方法为矩阵。

​		基于矩阵的标识，可以借鉴线性代数中矩阵分解的知识，通过矩阵分解挖掘用户和项目潜在（隐藏）因子的表示，即可以看作是对用户和项目的一种画像。



#### 2.1 奇异值分解

​		根据奇异值分解的观点，任何一个 $R_{m\times n}$ 矩阵都可以分解成正交矩阵 $U_{m\times m}$， 对角矩阵 $\Sigma_{m\times n}$ ，和正交矩阵 $V_{n\times n}$ 的乘积，即：
$$
R_{m\times n} = U_{m\times m}\times \Sigma_{m\times n}\times V_{n\times n}^T
$$
​		同时，如果奇异值分解之后，只保留前 k 个最大的奇异值，那么就能够实现对矩阵的降维，很多情况下，前 $10\%$ 甚至更少的奇异值的平方和就占全部奇异值平凡和的 $90\%$ 以上了，所以可以利用前 k 个奇异值和对应特征向量所包含的信息来近似描述原矩阵 $R$ ，这也就是截断奇异值分解的思想：
$$
R_{m\times n} \approx U_{m\times k}\times \Sigma_{k\times k}\times V_{n\times k}^T
$$
​		但是，进行 $SVD$ 分解需要知道完整的矩阵信息，由于用户评分行为的稀疏性，会导致评分矩阵中存在大量的缺失值，当矩阵信息不完整的时候，传统的 $SVD$ 方法不再适用。



#### 2.2 隐语义模型 LFM

​		隐语义模型灵感来源于 NLP 中的潜在语义分析 $(LSI)$ 的概念。

​		其理论基础为，任何一个矩阵 $R_{m\times n}$ 可以分解成两个矩阵的乘积，即：
$$
R_{m\times n} = X_{m\times k} \times Y_{n\times k}^T
$$
​		其中 $k = Rank(R)$。

​		在自然语言处理的潜在语义分析中，同过矩阵分解技术，将 **文本-单词** 分解为 **文本-话题** 矩阵和 **话题-单词** 的乘积，也就是从文本单词空间映射到文本话题空间。于是，再需要比较文本之间相似度的时候，可以根据文本之间话题的相似度来比较，可以大大减少计算量和存储占用。



​		***LFM 的基本思想***：

​		可以借助分解的性质，将用户和项目映射到同一隐藏的（潜在的）因子空间，这样便可以直接根据用户和项目进行比较，即直接计算用户和项目之间的相关度。挖掘（或学习）到隐藏因子可能有比较明显的维度，也可能有不明显的维度，但是对于用户来说，每个维度（因素）上的数值度量了用户在相应因素上喜欢项目的程度，而对于项目来说，每个维度（因素）上的数值度量了该项目在与该因素的相关性度。因此在训练集上学习，将用户和样本均映射到该因子空间，也就是给每一个用户和项目均用一个在该因子空间的向量表示，然后在预测阶段，根据用户和项目各自的向量表示最终计算用户对项目的评分等。

​		

​		***LFM 的数学描述***：

​		隐语义模型将用户与项目的交互（评分）建模成空间中的向量化內积，公式为：
$$
R_{m\times n}=P_{m\times d}\times Q_{n\times d}^T
$$
​		m 表示用户数目， n 表示项目数目，d 表示隐含空间的维度，因为很难确定 R 的秩，所以一般人工设定，不会设置太大。

​		学习目标是最小化均方误差损失函数：
$$
min_{P,Q} \sum_{(u, i)\in S}(r_{ui}-p_u^Tq_i)^2
$$
​		其中 $r_{ui}$ 是实际评分，S 表示已知（观测到）的 $user-item$ 评分集合，或者训练集的评分集合。而 $p_u$ 表示 $P^T$ 的第 $u$ 列，也就是第 $u$ 个用户在隐含空间中的向量表示 （写成这种形式是为了方便后面推导梯度下降公式），$q_i$ 表示 $Q^T $ 的第 $i$ 列，也就是第 $i$ 个项目在隐含空间中的表示，则 $p_u^Tq_i$ 即表示预测的评分值 $\hat r_{ui}$。为了避免过拟合，通常需要会加入正则化，公式变成：
$$
min_{P,Q} \sum_{(u, i)\in S}\ \ (r_{ui}-p_u^Tq_i)^2+\lambda[\ ||p||^2_F\ +\ ||Q||^2_F\ ]
$$
或者写成：
$$
min_{P,Q} \sum_{(u, i)\in S}(r_{ui}-p_u^Tq_i)^2+\lambda[\ \sum_{u=1}^mp_u^Tp_u +\sum_{i=1}^nq_i^Tq_i\ ]
$$
​	

​		***LFM的学习算法：***

​		可以采用 **随机梯度下降法（SGD）**或者 **交替最小二乘法（ALS）**，此处只介绍随机梯度下降法。

​		随机梯度下降每次从训练集中随机抽取一个（或一组）样本，计算预测误差（或损失），并根据梯度更新参数；然后再抽取一个样本，计算预测误差和梯度，并根据新梯度再次更新参数；如此反复，直至收敛（参数不再变化）或者是迭代次数达到预设最大值。

​		很容易理解，如果选中的样本是 $(u,\ i,\ r_{ui})$ ，则很好理解，只会对 $p_u$ 和 $q_i$ 进行更新：
$$
L_{ui}=(r_{ui}-p_u^Tq_i)^2+\lambda\ p_u^Tp_u\ +\ \lambda\ q_i^Tq_i
$$


​		很容易求出梯度为：
$$
\frac{\partial L_{ui}}{\partial p_u} =\ -2\times(r_{ui}-p_u^Tq_i)q_i + 2\lambda p_u \\ \frac{\partial L_{ui}}{\partial q_i} =\ -2\times(r_{ui}-p_u^Tq_i)p_u + 2\lambda q_i
$$
​		如果学习率为 $\alpha$，则更新方程为：
$$
p_u\leftarrow (1-2\lambda\alpha)p_u +2\alpha(r_{ui}-p_u^Tq_i)q_i \\ q_i\leftarrow (1-2\lambda\alpha)q_i +2\alpha(r_{ui}-p_u^Tq_i)p_u
$$



#### 2.3 概率矩阵分解 PMF

​		传统的矩阵分解算法存在一些弊端，一是不能处理大量的数据，二是不能处理只有很少评分的用户；并且由于噪声的存在，导致不可能得到完美的矩阵分解。根据贝叶斯学派的观点，可以将评分矩阵 $R$ 看作是观测值 (模型输入)，将用户隐特征矩阵 $U$ 和项目隐特征 $V$ 看作是系统内部特征，是需要估计的参数。

​		**PMF算法的假设：**

​		概率矩阵分解算法将用户评分矩阵 $R_{m\times n} $ 矩阵和用户特征矩阵 $U_{m\times d}$ 和项目特征矩阵 $V_{d\times n}$ 矩阵看作是随机变量，并有以下重要假设：

​		**1. $U$ 和 $V$ 均服从均值为 0 的高斯分布，即 $P_{U}=N(0, \sigma^2_U)$**，$P_V=N(0,\sigma^2_V)$

​		**2. 观测噪声（即实际评分矩阵 $R$ 和预测矩阵 $\hat R$ 的差值) 服从均值为 0 的高斯分布：$N(0,\sigma^2_R)$** 

​		于是可以得到，在 $U$ 和 $V$ 确定的情况下，$R$ 的概率密度函数为 $P(R\ |\ U,\ V)=N(UV^T,\ \sigma^2_R)$

​		假设每个用户的特征向量独立同分布，则有：（其中 $I$ 是单位对角矩阵，每一个用户的特征向量应该是服从 $d$ 维高斯分布，因为各个分量也相互独立，所以 $\sigma^2_UI$ 即表示各个分量的协方差矩阵）
$$
P(U|\sigma^2_U)=\prod_{i=1}^m N(U_i\ |\ 0,\ \sigma^2_UI)
$$
​		类似的，假设每个项目的特征向量独立同分布，则有：
$$
P(V|\sigma^2_V)=\prod_{i=1}^n N(V_i\ |\ 0,\ \sigma^2_VI)
$$
​		假设 $R$ 中的每个评分值是独立同分布的，则：（其中 $I_{ij}$ 指示是否产生过评分）
$$
P(R|U,V,\sigma^2_R)=\prod_{i=1}^m \prod_{j=1}^n [N(R_{ij}|U_iV_j^T,\sigma^2_R)]^{I_{ij}}
$$
​		

​		根据贝叶斯法则，我们有：
$$
P(U,V|R,\sigma^2_R,\sigma^2_U,\sigma^2_V)=P(R|U,V,\sigma^2_R,\sigma^2_U,\sigma^2_V)\times P(U,V)/P(R,\sigma^2_R,\sigma^2_U,\sigma^2_V)
$$
​		即：
$$
P(U,V|R,\sigma^2_R,\sigma^2_U,\sigma^2_V)\backsim \prod_{i=1}^m \prod_{j=1}^n [N(R_{ij}|U_iV_j^T,\sigma^2_R)]^{I_{ij}} \prod_{i=1}^m N(U_i\ |\ 0,\ \sigma^2_UI) \prod_{i=1}^n N(V_i\ |\ 0,\ \sigma^2_VI)
$$
​		对数似然函数为：
$$
\ln P(U,V|R,\sigma^2_R,\sigma^2_U,\sigma^2_V)=\sum_{i=1}^m\sum_{j=1}^n I_{ij}\ln(N(R_{ij}|U_iV_j^T,\sigma^2_R))\ +\ \sum_{i=1}^m\ln(N(U_i\ |\ 0,\ \sigma^2_UI))\ +\ \sum_{j=1}^n\ln(N(V_i\ |\ 0,\ \sigma^2_VI))
$$
​		进一步化简得：（C为常数)
$$
\ln P(U,V|R,\sigma^2_R,\sigma^2_U,\sigma^2_V)=-\frac{1}{2\sigma^2_R}(\sum_{i=1}^m\sum_{j=1}^n I_{ij}(R_{ij}-U_i^TV_j))-\frac{1}{2\sigma^2_U}\sum_{i=1}^mU^T_iU_i-\frac{1}{2\sigma^2_V}\sum_{j=1}^nV^T_jV_j\ +\ C
$$
​		于是，极大化对数似然函数等价于极小化：
$$
J=\frac{1}{2\sigma^2_R}(\sum_{i=1}^m\sum_{j=1}^n I_{ij}(R_{ij}-U_i^TV_j))+\frac{1}{2\sigma^2_U}\sum_{i=1}^mU^T_iU_i+\frac{1}{2\sigma^2_V}\sum_{j=1}^nV^T_jV_j
$$
​		令：$\lambda_U=\frac{\sigma_R^2}{\sigma_U^2}$，$\lambda_V=\frac{\sigma_R^2}{\sigma_V^2}$，则等价于极小化：
$$
J=\frac{1}{2}(\sum_{i=1}^m\sum_{j=1}^n I_{ij}(R_{ij}-U_i^TV_j))+\frac{\lambda_U}{2}\sum_{i=1}^m||U_i||_F^2+\frac{\lambda_V}{2}\sum_{j=1}^n||V_j||^2_F
$$
​		可见，概率矩阵分解的极大似然估计和带正则化项的隐语义模型在数学上是等价的。$PMF$ 从概率生成的角度解释用户和项目的隐语义表示，而 $LFM$ 从优化目标出发确定用户和项目隐语义表示以使预测误差最小化。

​		

#### 2.3 BiasSVD

​		$PMF$ 模型又被称为 $FunkSVD$ ，在此之后，出现了很多该算法的改算法，其中一个就是 $BiasSVD$。

​		注意以下事实，我们观测到的评分大部分都是跟用户与项目之间的关系度无关的因素产生，也就是很大一部分因素是和用户对物品的喜好无关而只取决于用户或项目本身的特性。例如，对于乐观的用户来说，评分普遍比较高，而对于批判性的用户来说，其评分普遍比较低，即使他们对于相同的项目的喜好程度是相同的，但是评分确实不一样的。另外，对项目来说也是类似的，受大众欢迎的项目得到的评分普遍比较高，但是一些不受大众欢迎项目评分普遍比较低。

​		$BiasSVD$ 将上面这些因素称为偏置项，将用户和项目交互的部分称为个性化部分。

​		偏置部分分为三个方面：

- 训练集中所有评分的全局平均数 $\mu$，表示了训练数据的整体评分情况，对于一个固定的数据集，这是一个常数。

- 用户偏置项 $b_u$，独立于物品特征的因素，表示某一特定用户的打分习惯。
- 项目偏置项 $b_i$，独立于用户兴趣的因素，表示某一特定物品的打分情况。



​		考虑所有偏置项之后，预测评分为：
$$
\hat r_{ui}=\mu+b_u+b_i+p_u^Tq_i
$$
​		学习算法与 $LFM$ 算法的 随机梯度下降算法类似，如果选中的样本是 $(u,\ i,\ r_{ui})$ ，则很好理解，只会对 $p_u$ 、 $q_i$ 以及 $b_u$、$b_i$ 进行更新：
$$
L_{ui}=(r_{ui}-\hat r_{ui})^2+\lambda\ p_u^Tp_u\ +\ \lambda\ q_i^Tq_i\ +\ \lambda b_u^2\ +\ \lambda  b_i^2
$$


​		很容易求出梯度为：
$$
\frac{\partial L_{ui}}{\partial p_u} =\ -2\times(r_{ui}-\hat r_{ui})q_i + 2\lambda p_u \\ \frac{\partial L_{ui}}{\partial q_i} =\ -2\times(r_{ui}-\hat r_{ui})p_u + 2\lambda q_i \\ \frac{\partial L_{ui}}{\partial b_u}=-2\times (r_{ui}-\hat r_{ui})\ +\ 2\lambda b_u \\ \frac{\partial L_{ui}}{\partial b_i}=-2\times (r_{ui}-\hat r_{ui})\ +\ 2\lambda b_i
$$
​		如果学习率为 $\alpha$，则更新方程为：
$$
p_u\leftarrow (1-2\lambda\alpha)p_u +2\alpha(r_{ui}-\hat r_{ui})q_i \\ q_i\leftarrow (1-2\lambda\alpha)q_i +2\alpha(r_{ui}-\hat r_{ui})p_u \\ b_u\leftarrow (1-2\lambda\alpha)b_u +2\alpha(r_{ui}-\hat r_{ui}) \\ b_i\leftarrow (1-2\lambda\alpha)b_i +2\alpha(r_{ui}-\hat r_{ui})
$$



#### 2.4 SVD + +

​		$SVD++$ 模型是对 $BiasSVD$ 模型的进一步改进，引入了隐式反馈和用户属性信息，相当于引入了额外的信息源头。这样可以从侧面反映用户的偏好，能够解决因显式评分行为较少导致的冷启动问题。

​		其假设推荐系统可以使用隐式反馈信息来帮助了解用户的显式评分偏好。无论用户是否愿意提供明确的评分数据，推荐系统都可以收集他们的行为信息，比如浏览历史、收藏信息等等。这些隐式反馈信息都从某些方面反映了用户的偏好特征。这对于那些提供了大量隐式反馈而只是提供了少量的显式反馈的用户显得尤其重要。为此，$SVD++$ 模型在 $BiasSVD$ 模型的基础上，增加了第二个项目因子集合，即为每一个项目 $i$ 关联一个因子向量 $y_i$，用以表示如果用户对项目 $i$ 有过隐式反馈，那么用户就具有特征 $y_i$。于是，$SVD++$ 模型的评分预测公式为：
$$
\hat r_{ui} =\mu\ +\ b_u\ +\ b_i \ +\ (p_u+\frac{\sum_{j\in R_{(u)}}y_j}{\sqrt{|R_{(u)}|}})^Tq_i
$$


​		其中 $R_{(u)}$ 表示用户 $u$ 有过隐式反馈的项目集合。当没有其他可用信息时，可以表示用户 $u$ 评分过的项目集合。

​		同样可以利用随机梯度下降算法进行模型的学习和优化。如果选中的样本是 $(u,\ i,\ r_{ui})$ ，则很好理解，只会对 $p_u$ 、 $q_i$ 以及 $b_u$、$b_i$ ，还有 $R_{(u)}$ 中的项目对应的特征 $y$ 进行更新。
$$
\frac{\partial L_{ui}}{\partial p_u} =\ -2\times(r_{ui}-\hat r_{ui})q_i + 2\lambda p_u \\ \frac{\partial L_{ui}}{\partial q_i} =\ -2\times(r_{ui}-\hat r_{ui})p_u + 2\lambda q_i \\ \frac{\partial L_{ui}}{\partial b_u}=-2\times (r_{ui}-\hat r_{ui})\ +\ 2\lambda b_u \\ \frac{\partial L_{ui}}{\partial b_i}=-2\times (r_{ui}-\hat r_{ui})\ +\ 2\lambda b_i \\ \frac{\partial L_{ui}}{\partial y_j} =\ -\frac{2}{\sqrt{|R_{(u)}|}}\times(r_{ui}-\hat r_{ui})q_i + 2\lambda y_j,\ \ for \ \ j\in R_{(u)}		
$$
​		如果学习率为 $\alpha$，则更新方程为：
$$
p_u\leftarrow (1-2\lambda\alpha)p_u +2\alpha(r_{ui}-\hat r_{ui})q_i \\ q_i\leftarrow (1-2\lambda\alpha)q_i +2\alpha(r_{ui}-\hat r_{ui})p_u \\ b_u\leftarrow (1-2\lambda\alpha)b_u +2\alpha(r_{ui}-\hat r_{ui}) \\ b_i\leftarrow (1-2\lambda\alpha)b_i +2\alpha(r_{ui}-\hat r_{ui}) \\ y_j\leftarrow(1-2\lambda\alpha)y_j\ +\ \frac{2\alpha}{\sqrt{|R_{(u)}|}}(r_{ui}-\hat r_{ui})q_i,\ \ \ for\ \ j\in R(u)
$$



## 3. 基于矩阵分解的 TopN 推荐

​		隐式反馈更容易获取，数据量更大，但是也更加难以分析，具体而言，隐式反馈具有以下特征：

1. **没有负反馈（负样本）**。也就是说用户没有隐式反馈的项目不一定是用户不喜欢或者不感兴趣的项目，因为用户可能因为某些其他原因而没有和项目交互。
2. **隐士反馈包含噪声比较多**。显式的用户评分行为是用户强烈的主动行为，而隐式反馈的用户行为可能会收到其他很多因素的影响，比如误操作，比如虽然浏览了，但是用户并不喜欢这个项目。
3. **显式反馈代表用户真实的喜好程度，隐式反馈代表置信度**。



#### 3.1 基于正样本过采样的矩阵分解

​		隐式反馈没有负样本，一种常用的做法是将未观测到反馈的样本作为负样本。但是由于每个用户的样本数一般都比较少，导致正样本和负样本的比例极度不均衡。

​		为了解决正负样本不均衡的问题，$WRMF$ 算法通过对正样本过采样，构建一个新的目标函数：
$$
\min_{p,q}\sum_{u,i}c_{ui}(r_{ui}-<p_u,q_i>)^2\ +\ \lambda(||P||^2_F\ +\ ||Q||^2_F)
$$
​		上式中，$c_{ui}$ 表示置信度，对于 $r_{ui} = 0$ 的用户项目对，模型认为用户 $u$ 不喜欢 $i$ 的置信度较低，因为用户可能是因为其他原因而导致没有反馈数据，而不是因为用户不喜欢该项目。对于 $r_{ui}=1$，即观测到反馈行为的用户项目对，模型认为用户 $u$ 喜欢该项目的置信度比较高。$c_{ui}$ 一般设置为：
$$
c_{ui}=1\ +\ \alpha r_{ui}
$$
​		式中，$\alpha$ 是一个超参数，一般设置为 40。

​		可以使用交替最小二乘法 $(ALS)$ 进行求解。

​		本质上 $WRMF$ 算法是对正样本进行过采样，超参数 $\alpha$ 即表示每个正样本重复采样的次数。这种方式能都在一定程度上解决正负样本不均衡的问题，但是还是假设每个未观测反馈的样本（确实数据）是负样本。然而在实际中，这些未观测到反馈的样本包含额了一些用户喜欢的项目，而可能只是用户自己没有看到而已。此外，由于确实数据通常很多（数据稀疏问题），将所有的缺失数据都视为负样本，将造成数据规模非常大，处理时间复杂度很高，无法在大数据集上工作。



#### 3.2 基于负样本欠采样的矩阵分解

​		针对正负样本不均衡问题的另一个解决方案就是对负样本进行欠采样，即对未观测到反馈行为的样本中采样出一个和正样本集合差不多大小的负样本集合。有三种常用的负样本采样方法：

1. **随机均匀采样**。假设每个未观测到反馈的样本都是负样本且影响相同；
2. **面向用户采样**。若用户购买了更多的项目，那么他还没有反馈过的项目就有更高的可能是负样本；
3. **面向项目采样**。一个项目越热门，用户越有可能知道它的存在，这种情况下用户还没有对它有过反馈行为，则表明这很可能是真正的负样本。



​		如果采用 $ALS$ 作为模型参数学习的算法，那么就可以采用和上面类似的目标函数，引入样本权重因子矩阵 $W$ 表示置信度，置信度具有如下特征：

|              | 正反馈 |     “负”反馈      |
| :----------: | :----: | :---------------: |
| 随机均匀采样 | W = 1  |    0 =< W <= 1    |
| 面向用户采样 | W = 1  | W正比于用户活跃度 |
| 面向项目采样 | W = 1  | W正比于项目热门度 |

$$
\min_{p,q}\sum_{u,i}W_{ui}(r_{ui}-<p_u,q_i>)^2\ +\ \lambda(||P||^2_F\ +\ ||Q||^2_F)
$$

​		如果采用 $SGD$ 算法作为模型学习算法，则可以定义如下目标函数：
$$
\min \sum_{r_{ui}\in R_+\cup R_-}(r_{ui}-p_u^Tq_i)^2+\lambda(\sum_up_u^Tp_u\ +\ \sum_iq_i^Tq_i)
$$
​		其中 $R_+$ 表示正样本，$R_-$ 表示负样本，以权重因子作为采样概率。

​		